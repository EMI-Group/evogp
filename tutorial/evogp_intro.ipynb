{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EvoGP Tutorial: Getting Started with Tree-Based Genetic Programming\n",
    "\n",
    "This tutorial will guide you through using EvoGP for tree-based genetic programming (TGP), showcasing key features such as tree generation, problem definition, and algorithm customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import torch\n",
    "from evogp.tree import Forest, GenerateDiscriptor\n",
    "from evogp.problem import SymbolicRegression, Classification\n",
    "from evogp.algorithm import *\n",
    "from evogp.pipeline import StandardPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Introduction to Tree Generation\n",
    "\n",
    "#### Understanding the `GenerateDiscriptor` Class Parameters\n",
    "\n",
    "The `GenerateDiscriptor` class helps configure the parameters for tree generation. Let’s understand its arguments:\n",
    "\n",
    "- **`max_tree_len`**: This parameter specifies the maximum number of nodes that the tree can have. It helps control the tree’s size and complexity.\n",
    "\n",
    "- **`input_len`**: The number of input variables that the tree will take. This defines how many features or input dimensions the tree will work with.\n",
    "\n",
    "- **`output_len`**: The number of outputs the tree will produce. This is used when dealing with multiple outputs problems.\n",
    "\n",
    "- **`const_prob`**: This is the probability that a node in the tree will be a constant value, rather than input. A higher value means more constants are likely to appear in the tree.\n",
    "\n",
    "- **`out_prob`**: The probability that a node in the tree will be an output node. This helps define how many nodes in the tree will directly correspond to outputs.\n",
    "\n",
    "- **`depth2leaf_probs`**: A tensor that specifies the probability distribution for the tree’s growth at different depths. If not provided, it will be generated based on other parameters such as `max_layer_cnt` and `layer_leaf_prob`.\n",
    "\n",
    "- **`roulette_funcs`**: A tensor that represents the cumulative probability distribution for selecting different functions (such as addition, subtraction, etc.) at each node. If not provided, it will be built from the `using_funcs` parameter.\n",
    "\n",
    "- **`const_samples`**: This parameter contains the constant values that can be used in the tree. It can be either a list or a tensor of pre-defined constants. If not provided, the constants will be generated within the range defined by `const_range` and `sample_cnt`.\n",
    "\n",
    "- **`using_funcs`**: A dictionary or list of functions that will be available for use at each node of the tree. If `roulette_funcs` is not provided, this parameter will be used to build it.\n",
    "\n",
    "- **`max_layer_cnt`**: The maximum number of layers that the tree can have. This is used when `depth2leaf_probs` is not provided, helping to control the tree’s depth and structure.\n",
    "\n",
    "- **`layer_leaf_prob`**: The probability of a node being a leaf at each layer in the tree. This is used if `depth2leaf_probs` is not provided.\n",
    "\n",
    "- **`const_range`**: A tuple that defines the range from which constant values can be sampled. This is used if `const_samples` is not provided.\n",
    "\n",
    "- **`sample_cnt`**: The number of constant samples to generate if `const_samples` is not provided. This works in conjunction with `const_range `to define the distribution of constants.\n",
    "\n",
    "After initializing the `GenerateDiscriptor` class with the above parameters, they will be aggregated and processed into the following key parameters: `max_tree_len`, `input_len`, `output_len`, `const_prob`, `out_prob`, `depth2leaf_probs`, `roulette_funcs`, `const_samples`. These key parameters represent the most important aspects of the tree’s structure and behavior, which will be used throughout the genetic programming process.\n",
    "\n",
    "You can print these parameters and use the `GenerateDiscriptor` to generate a tree as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_tree_len: 64\n",
      "input_len: 2\n",
      "output_len: 1\n",
      "const_prob: 0.5\n",
      "out_prob: 0.5\n",
      "depth2leaf_probs: tensor([0.2000, 0.2000, 0.2000, 0.2000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], device='cuda:0')\n",
      "roulette_funcs: tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], device='cuda:0')\n",
      "const_samples: tensor([-1.,  0.,  1.], device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Forest(pop size: 1)\n",
       "[\n",
       "  / - / - x[1] 1.00 * 1.00 x[1] / x[0] x[0] / x[1] x[1] , \n",
       "]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptor = GenerateDiscriptor(\n",
    "    max_tree_len=64,\n",
    "    input_len=2,\n",
    "    output_len=1,\n",
    "    using_funcs=[\"+\", \"-\", \"*\", \"/\"],\n",
    "    max_layer_cnt=5,\n",
    "    const_samples=[-1, 0, 1]\n",
    ")\n",
    "print(descriptor)\n",
    "\n",
    "Forest.random_generate(1, descriptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the `update` Method\n",
    "\n",
    "The GenerateDiscriptor class also provides an `update` method, which allows you to modify the descriptor’s parameters after it has been initialized. This method takes any number of keyword arguments (i.e., **kwargs) and updates the descriptor’s internal parameter dictionary.\n",
    "\n",
    "Here’s how you can use the `update` method to generate a tree with the different configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_tree_len: 64\n",
      "input_len: 2\n",
      "output_len: 1\n",
      "const_prob: 0.5\n",
      "out_prob: 0.5\n",
      "depth2leaf_probs: tensor([0.2000, 0.2000, 0.2000, 0.2000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], device='cuda:0')\n",
      "roulette_funcs: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.6667, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], device='cuda:0')\n",
      "const_samples: tensor([-1.,  0.,  1.], device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Forest(pop size: 1)\n",
       "[\n",
       "  cos 0.00 , \n",
       "]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_descriptor = descriptor.update(using_funcs=[\"sin\", \"cos\", \"tan\"])\n",
    "print(new_descriptor)\n",
    "\n",
    "Forest.random_generate(1, new_descriptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Defining Problems\n",
    "\n",
    "EvoGP supports various problem types:\n",
    "\n",
    "#### a. Symbolic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((100, 2), device=\"cuda\")\n",
    "y = X[:, 0] ** 2 + 2 * X[:, 1]\n",
    "problem = SymbolicRegression(datapoints=X, labels=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "X = torch.tensor(data.data, dtype=torch.float, device=\"cuda\")\n",
    "y = torch.tensor(data.target, dtype=torch.float, device=\"cuda\")\n",
    "problem = Classification(datapoints=X, labels=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Custom Functions\n",
    "You can also create problems with custom functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_function(x):\n",
    "    y = (x[0] + x[1]) ** 2\n",
    "    return y.reshape(-1)\n",
    "\n",
    "problem = SymbolicRegression(\n",
    "    func=custom_function,\n",
    "    num_inputs=2,\n",
    "    num_data=1000,\n",
    "    lower_bounds=-5,\n",
    "    upper_bounds=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Customizing Algorithms\n",
    "\n",
    "EvoGP provides flexibility through its genetic operators.\n",
    "\n",
    "#### Default Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = GeneticProgramming(\n",
    "    initial_forest=Forest.random_generate(pop_size=1000, descriptor=descriptor),\n",
    "    crossover=DefaultCrossover(),\n",
    "    mutation=DefaultMutation(mutation_rate=0.2, descriptor=descriptor),\n",
    "    selection=DefaultSelection(survival_rate=0.3, elite_rate=0.01)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Variants\n",
    "- Selection: `RouletteSelection`, `TruncationSelection`, `RankSelection`, `TournamentSelection`\n",
    "- Crossover: `DiversityCrossover`, `LeafBiasedCrossover`\n",
    "- Mutation: `HoistMutation`, `SinglePointMutation`, `MultiPointMutation`, `InsertMutation`, `DeleteMutation`, `SingleConstMutation`, `MultiConstMutation`, `CombinedMutation`\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = GeneticProgramming(\n",
    "    initial_forest=Forest.random_generate(pop_size=1000, descriptor=descriptor),\n",
    "    crossover=LeafBiasedCrossover(),\n",
    "    mutation=CombinedMutation(\n",
    "        [\n",
    "            DefaultMutation(mutation_rate=0.2, descriptor=descriptor),\n",
    "            HoistMutation(mutation_rate=0.2),\n",
    "            # MultiPointMutation(mutation_rate=0.2, generate_configs=descriptor),\n",
    "        ]\n",
    "    ),\n",
    "    selection=TournamentSelection(5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Running the Pipeline\n",
    "\n",
    "Finally, run the algorithm on the defined problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 0, Cost time: 7.21ms\n",
      " \tfitness: valid cnt: 756, max: -188.6561, min: -19421176.0000, mean: -199233.5312, std: 1490983.7500\n",
      "\n",
      "Generation: 1, Cost time: 6.99ms\n",
      " \tfitness: valid cnt: 887, max: -188.6561, min: -40845316.0000, mean: -117376.6406, std: 1648821.0000\n",
      "\n",
      "Generation: 2, Cost time: 7.61ms\n",
      " \tfitness: valid cnt: 907, max: -119.5990, min: -19424844.0000, mean: -86082.8516, std: 1022529.0625\n",
      "\n",
      "Generation: 3, Cost time: 6.51ms\n",
      " \tfitness: valid cnt: 911, max: -101.9342, min: -79571184.0000, mean: -139997.1406, std: 2735153.0000\n",
      "\n",
      "Generation: 4, Cost time: 8.01ms\n",
      " \tfitness: valid cnt: 923, max: -42.4933, min: -21450938.0000, mean: -132339.8594, std: 1278990.7500\n",
      "\n",
      "Generation: 5, Cost time: 6.98ms\n",
      " \tfitness: valid cnt: 928, max: -42.4933, min: -13671805.0000, mean: -70466.0312, std: 729242.5625\n",
      "\n",
      "Generation: 6, Cost time: 6.97ms\n",
      " \tfitness: valid cnt: 934, max: -8.3302, min: -90824408.0000, mean: -221391.4062, std: 3544131.7500\n",
      "\n",
      "Generation: 7, Cost time: 7.40ms\n",
      " \tfitness: valid cnt: 935, max: -8.7377, min: -90824408.0000, mean: -238535.6562, std: 4049603.7500\n",
      "\n",
      "Generation: 8, Cost time: 7.76ms\n",
      " \tfitness: valid cnt: 937, max: -1.0000, min: -49462264.0000, mean: -161902.1875, std: 2325132.5000\n",
      "\n",
      "Generation: 9, Cost time: 7.34ms\n",
      " \tfitness: valid cnt: 958, max: -0.0000, min: -51972848.0000, mean: -98129.9219, std: 1869292.1250\n",
      "\n",
      "Generation: 10, Cost time: 8.65ms\n",
      " \tfitness: valid cnt: 952, max: -0.0000, min: -38772788.0000, mean: -68360.7812, std: 1362629.8750\n",
      "\n",
      "Generation: 11, Cost time: 9.03ms\n",
      " \tfitness: valid cnt: 948, max: -0.0000, min: -16418644.0000, mean: -47124.4961, std: 691496.6250\n",
      "\n",
      "Generation: 12, Cost time: 9.65ms\n",
      " \tfitness: valid cnt: 943, max: -0.0000, min: -6568996.0000, mean: -17274.1797, std: 238921.4062\n",
      "\n",
      "Generation: 13, Cost time: 8.26ms\n",
      " \tfitness: valid cnt: 954, max: -0.0000, min: -43275660.0000, mean: -86540.0078, std: 1562535.6250\n",
      "\n",
      "Generation: 14, Cost time: 10.22ms\n",
      " \tfitness: valid cnt: 946, max: -0.0000, min: -68309304.0000, mean: -179997.0156, std: 2748322.7500\n",
      "\n",
      "Generation: 15, Cost time: 7.77ms\n",
      " \tfitness: valid cnt: 949, max: -0.0000, min: -35288112.0000, mean: -189814.6250, std: 2061397.0000\n",
      "\n",
      "Generation: 16, Cost time: 7.71ms\n",
      " \tfitness: valid cnt: 953, max: -0.0000, min: -26797204.0000, mean: -125131.1484, std: 1574419.5000\n",
      "\n",
      "Generation: 17, Cost time: 7.75ms\n",
      " \tfitness: valid cnt: 964, max: -0.0000, min: -77656632.0000, mean: -134000.2188, std: 2579646.2500\n",
      "\n",
      "Generation: 18, Cost time: 8.08ms\n",
      " \tfitness: valid cnt: 957, max: -0.0000, min: -19423328.0000, mean: -62020.8711, std: 920671.4375\n",
      "\n",
      "Generation: 19, Cost time: 8.22ms\n",
      " \tfitness: valid cnt: 962, max: -0.0000, min: -11702395.0000, mean: -43188.5312, std: 574789.8750\n",
      "\n",
      "Generation: 20, Cost time: 7.99ms\n",
      " \tfitness: valid cnt: 966, max: -0.0000, min: -17901162.0000, mean: -35652.8867, std: 603466.6250\n",
      "\n",
      "Generation: 21, Cost time: 8.21ms\n",
      " \tfitness: valid cnt: 964, max: -0.0000, min: -32231192.0000, mean: -59172.0898, std: 1103072.6250\n",
      "\n",
      "Generation: 22, Cost time: 8.48ms\n",
      " \tfitness: valid cnt: 964, max: -0.0000, min: -78429048.0000, mean: -104256.1484, std: 2533728.5000\n",
      "\n",
      "Generation: 23, Cost time: 8.31ms\n",
      " \tfitness: valid cnt: 957, max: -0.0000, min: -32016570.0000, mean: -51996.2852, std: 1049072.1250\n",
      "\n",
      "Generation: 24, Cost time: 8.45ms\n",
      " \tfitness: valid cnt: 975, max: -0.0000, min: -18099656.0000, mean: -54383.3516, std: 740374.4375\n",
      "\n",
      "Generation: 25, Cost time: 9.37ms\n",
      " \tfitness: valid cnt: 956, max: -0.0000, min: -54849308.0000, mean: -108922.3516, std: 1930845.1250\n",
      "\n",
      "Generation: 26, Cost time: 10.62ms\n",
      " \tfitness: valid cnt: 941, max: -0.0000, min: -19436028.0000, mean: -31352.6230, std: 644384.4375\n",
      "\n",
      "Generation: 27, Cost time: 10.81ms\n",
      " \tfitness: valid cnt: 955, max: -0.0000, min: -19436028.0000, mean: -34162.9609, std: 649776.8125\n",
      "\n",
      "Generation: 28, Cost time: 7.87ms\n",
      " \tfitness: valid cnt: 950, max: -0.0000, min: -13312700.0000, mean: -34539.8906, std: 484607.2188\n",
      "\n",
      "Generation: 29, Cost time: 9.73ms\n",
      " \tfitness: valid cnt: 958, max: -0.0000, min: -4806022.5000, mean: -17161.5293, std: 206872.1875\n",
      "\n",
      "Generation: 30, Cost time: 7.80ms\n",
      " \tfitness: valid cnt: 962, max: -0.0000, min: -19421776.0000, mean: -70572.7578, std: 879374.0000\n",
      "\n",
      "Generation: 31, Cost time: 7.89ms\n",
      " \tfitness: valid cnt: 950, max: -0.0000, min: -2733847.5000, mean: -25086.4473, std: 198608.0938\n",
      "\n",
      "Generation: 32, Cost time: 7.64ms\n",
      " \tfitness: valid cnt: 950, max: -0.0000, min: -6158735.5000, mean: -18510.9238, std: 245274.1250\n",
      "\n",
      "Generation: 33, Cost time: 9.22ms\n",
      " \tfitness: valid cnt: 960, max: -0.0000, min: -19422140.0000, mean: -74901.4141, std: 883132.9375\n",
      "\n",
      "Generation: 34, Cost time: 7.61ms\n",
      " \tfitness: valid cnt: 947, max: -0.0000, min: -42216916.0000, mean: -60407.0039, std: 1380040.5000\n",
      "\n",
      "Generation: 35, Cost time: 9.10ms\n",
      " \tfitness: valid cnt: 953, max: -0.0000, min: -12878946.0000, mean: -27876.6113, std: 442347.0625\n",
      "\n",
      "Generation: 36, Cost time: 8.47ms\n",
      " \tfitness: valid cnt: 960, max: -0.0000, min: -19420122.0000, mean: -57257.4883, std: 854391.5625\n",
      "\n",
      "Generation: 37, Cost time: 12.61ms\n",
      " \tfitness: valid cnt: 944, max: -0.0000, min: -19093242.0000, mean: -30501.1953, std: 634721.3125\n",
      "\n",
      "Generation: 38, Cost time: 10.38ms\n",
      " \tfitness: valid cnt: 959, max: -0.0000, min: -21387762.0000, mean: -40440.8789, std: 750384.7500\n",
      "\n",
      "Generation: 39, Cost time: 7.61ms\n",
      " \tfitness: valid cnt: 955, max: -0.0000, min: -14304386.0000, mean: -25571.7324, std: 472526.3125\n",
      "\n",
      "Generation: 40, Cost time: 10.27ms\n",
      " \tfitness: valid cnt: 955, max: -0.0000, min: -36532880.0000, mean: -104003.2031, std: 1498777.8750\n",
      "\n",
      "Generation: 41, Cost time: 8.05ms\n",
      " \tfitness: valid cnt: 938, max: -0.0000, min: -36488096.0000, mean: -78063.3750, std: 1402508.3750\n",
      "\n",
      "Generation: 42, Cost time: 8.74ms\n",
      " \tfitness: valid cnt: 950, max: -0.0000, min: -36488096.0000, mean: -69784.4453, std: 1346562.5000\n",
      "\n",
      "Generation: 43, Cost time: 7.61ms\n",
      " \tfitness: valid cnt: 930, max: -0.0000, min: -2782690.0000, mean: -13831.2852, std: 154912.8594\n",
      "\n",
      "Generation: 44, Cost time: 10.20ms\n",
      " \tfitness: valid cnt: 949, max: -0.0000, min: -57219620.0000, mean: -82449.8516, std: 1870295.0000\n",
      "\n",
      "Generation: 45, Cost time: 7.61ms\n",
      " \tfitness: valid cnt: 952, max: -0.0000, min: -11124376.0000, mean: -36889.2266, std: 497148.5312\n",
      "\n",
      "Generation: 46, Cost time: 8.00ms\n",
      " \tfitness: valid cnt: 941, max: -0.0000, min: -60794368.0000, mean: -122814.2969, std: 2178982.2500\n",
      "\n",
      "Generation: 47, Cost time: 7.59ms\n",
      " \tfitness: valid cnt: 943, max: -0.0000, min: -52199248.0000, mean: -94183.7812, std: 1824112.5000\n",
      "\n",
      "Generation: 48, Cost time: 8.76ms\n",
      " \tfitness: valid cnt: 961, max: -0.0000, min: -47586180.0000, mean: -111189.4844, std: 1747215.5000\n",
      "\n",
      "Generation: 49, Cost time: 7.60ms\n",
      " \tfitness: valid cnt: 954, max: -0.0000, min: -62095428.0000, mean: -93018.7734, std: 2075981.2500\n",
      "\n",
      "Generation limit reached!\n"
     ]
    }
   ],
   "source": [
    "pipeline = StandardPipeline(\n",
    "    algorithm,\n",
    "    problem,\n",
    "    generation_limit=50\n",
    ")\n",
    "\n",
    "best = pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5: Inspecting Results\n",
    "\n",
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([34.9353], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "predictions = best.forward(problem.datapoints[0])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symbolic Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x0 + x1)*(x0 + 1.0*x1)\n"
     ]
    }
   ],
   "source": [
    "expression = best.to_sympy_expr()\n",
    "print(expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.to_png(\"best_tree.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evogp312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
